<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head>
	<meta name="generator" content="Hugo 0.129.0">
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width">
<title>Living Systems</title>

      <link rel="stylesheet" href="/css/main.min.f3a5991997d3edfa6612acd25887dbae0ca5be329567cceb3054217da27f5132.css" integrity="sha256-86WZGZfT7fpmEqzSWIfbrgylvjKVZ8zrMFQhfaJ/UTI=" crossorigin="anonymous">


      <script src="/js/main.23cd0c7d837263b9eaeb96ee2d9ccfa2969daa3fa00fa1c1fe8701a9b87251a1.js" integrity="sha256-I80MfYNyY7nq65buLZzPopadqj&#43;gD6HB/ocBqbhyUaE=" crossorigin="anonymous"></script>


</head>
<body>
  <header>
    <h1>Living Systems</h1>

  <nav>
    <ul>
    <li>
      <a aria-current="page" class="active" href="/">Home</a>
    </li>
    <li>
      <a href="/posts/">Posts</a>
    </li>
    <li>
      <a href="/tags/">Tags</a>
    </li>
    </ul>
  </nav>


  </header>
  <main>
    
  
  
    <div class="post-card">

<a href="/posts/ahc2024/"><img src="/posts/ahc2024//dsc_4779_2.jpg" class="post-img-list"></a>

<h2><a href="/posts/ahc2024/">A few notes from the Applied Hologenomics Conference 2024</a></h2>
I&rsquo;m just back from the Applied Hologenomics Conference in 2024 (See also #AHC2024 on Twitter) in Copenhagen and thought to reflect a little on the conference and highlight the bits that particularly stuck with me.
The first thing I want to say is that a paradigm shift is happening here.
I think what is happening here is a step away from the reductionist view of the past that goes beyond the systems biology approach that has been establishing itself during the last 10-20 years.
</div>

  
    <div class="post-card">

<a href="/posts/bioinformatics-recipes/"><img src="/posts/bioinformatics-recipes//bioinformaticsrecipes.jpg" class="post-img-list"></a>

<h2><a href="/posts/bioinformatics-recipes/">We need recipes for common bioinformatics tasks</a></h2>
Ad-hoc tasks in bioinformatics can contain such an immense number of operations and tasks that need to be performed to achieve a certain goal. Often these are all individually regarded as rather &quot;standard&quot; or &quot;routine&quot;. Despite this, it is quite hard to find an authoritative set of &quot;recipes&quot; for how to do such tasks.
Thus I was starting to think that there needs to be a collection of bioinformatics &quot;recipes&quot;. A sort of &quot;cookbook&quot; for common bioinformatics tasks.
</div>

  
    <div class="post-card">

<a href="/posts/golang-for-bioinformatics/"><img src="/posts/golang-for-bioinformatics//gopherbinfie.jpg" class="post-img-list"></a>

<h2><a href="/posts/golang-for-bioinformatics/">Why didn&#39;t Go get a breakthrough in bioinformatics (yet)?</a></h2>
As we are - according to some expert opinions - living in the Century of Biology, I found it interesting to reflect on Go's usage within the field.
Go has some great features that make it really well suited for biology, such as:
A relatively simple language that can be learned in a short time even for people without a CS background. This is super important aspect for biologists. Fantastic support for cross-compilation into all major computer architectures and operating systems, as static, self-sufficient executables making it extremely simple to deploy tools, something that can't be said about the currently most popular bio language, Python.
</div>

  
    <div class="post-card">

<a href="/posts/scipipe-at-nasa/"><img src="/posts/scipipe-at-nasa//nasa-paper.png" class="post-img-list"></a>

<h2><a href="/posts/scipipe-at-nasa/">SciPipe used at NASA Glenn Research Center</a></h2>
I was happy to see the publication finally going online, of work done at NASA Glenn Research Center, where SciPipe has been used to process and track provenance of the analyses, &quot;Modeling the impact of thoracic pressure on intracranial pressure&quot;. I've known the work existed for a couple of years, after getting some extraordinarily useful contributions from Drayton fixing some bugs I'm not sure I'd ever find otherwise, but cool to now also see it published!
</div>

  
    <div class="post-card">

<a href="/posts/debugging-inside-jinja-templates-using-pdb-ipdb/"><img src="/posts/debugging-inside-jinja-templates-using-pdb-ipdb//image-1.png" class="post-img-list"></a>

<h2><a href="/posts/debugging-inside-jinja-templates-using-pdb-ipdb/">Debugging inside Jinja templates using pdb/ipdb</a></h2>
I'm working on a static reporting tool using the Jinja2 templating engine for Python.
I was trying to figure out a way to enter into the Jinja templating code with the pdb/ipdb commandline debugger.
I tried creating an .ipdbrc file in my local directory with the line:
path/to/template.html:&lt;lineno&gt; ... but that didn't work.
What worked was to figure out the line that says:
return self.environment.concat(self.root_render_func(ctx)) ... inside the the jinja codebase, and put a breakpoint on that (which for me was on line 1299, but might vary depending on version):
</div>

  
    <div class="post-card">

<a href="/posts/scicommander-0.3/"><img src="/posts/scicommander-0.3//scicmd-poster-export-007.png" class="post-img-list"></a>

<h2><a href="/posts/scicommander-0.3/">SciCommander - track provenance of any shell command</a></h2>
I haven't written much about a new tool I've been working on in some extra time: SciCommander.
I just presented a poster about it at the Swedish Bioinformatics Workshop 2023 , so perhaps let me first present you the poster instead of re-iterating what it is (click to view large version):
New version not requiring running the scicmd command I got a lot of great feedback from numerous people at the conference, most of who pointed out that it would be great if one could start scicommander as a kind of subshell, inside which one can run commands as usual, instead of running them via the scicmd -c command.
</div>

  
    <div class="post-card">

<h2><a href="/posts/troubleshooting-nextflow-pipelines/">Troubleshooting Nextflow pipelines</a></h2>
We have been evaluating Nextflow before in my work at pharmb.io, but that was before DSL2 and the support for re-usable modules (which was one reason we needed to develop our own tools to support our challenges, as explained in the paper). Thus, there's definitely some stuff to get into.
Based on my years in bioinformatics and data science, I've seen that the number one skill that you need to develop is to be able to effectively troubleshoot things, because things will invariably fail in all kinds of ways.
</div>

  
    <div class="post-card">

<h2><a href="/posts/installing-and-configuring-debian-11-into-a-great-experience/">Random notes from installing Debian 11 with separate accounts for work and private</a></h2>
See especially the end for info about how to set up a nice integration between the work and private accounts, such that one can e.g. occasionally start the mail client or web browser from the private account from the work one etc.
Caveats when installing Debian 11 Make sure that an EFI partition is created (when I manually modified the partition table I accidentally deleted it, and had to reinstall to get it created properly again).
</div>

  
    <div class="post-card">

<a href="/posts/installing-qubes-os/"><img src="/posts/installing-qubes-os//qubes-installed.jpg" class="post-img-list"></a>

<h2><a href="/posts/installing-qubes-os/">Installing Qubes OS</a></h2>
I just switched to Qubes OS as operating system on my main work laptop (a Dell Latitude). Or in fact, one of the reasons was to be able to combine work and private hobby coding projects, that's increasinbly been happening on the same machine. Anyways, these are my experiences and notes, as a way to document caveats and quirks in case I need to do this again, while possibly also being of use for others.
</div>

  
    <div class="post-card">

<h2><a href="/posts/composability-in-functional-and-flow-based-programming/">Composability in functional and flow-based programming</a></h2>
An area where I'm not so happy with some things I've seen in FP, is composability.
In my view, a well designed system or langauge should make functions (or other smallest unit of computation) more easily composable, not less.
What strikes me as one of the biggest elephants in the room regarding FP, is that typical functions compose fantastically as long as you are working with a single input argument, and a single output for each function application, but as soon as you start taking multiple input arguments and returned outputs though, you tend to end up with very messy trees of function application.
</div>

  
    <div class="post-card">

<a href="/posts/crystal-concurrency-easier-syntax-than-golang/"><img src="/posts/crystal-concurrency-easier-syntax-than-golang//selection_161-1.png" class="post-img-list"></a>

<h2><a href="/posts/crystal-concurrency-easier-syntax-than-golang/">Crystal: Go-like concurrency with easier syntax</a></h2>
I have been playing around a lot with concurrency in Go over the years, resulting in libraries such as SciPipe, FlowBase and rdf2smw. My main motivation for looking into Go has been the possibility to use it as a more performant, scaleable and type-safe alternative to Python for data heavy scripting tasks in bioinformatics and other fields I've been dabbling in. Especially as it makes it so easy to write concurrent and parallel code in it.
</div>

  
    <div class="post-card">

<a href="/posts/go-test-coverage-in-browser/"><img src="/posts/go-test-coverage-in-browser//selection_150.png" class="post-img-list"></a>

<h2><a href="/posts/go-test-coverage-in-browser/">Viewing Go test coverage in the browser with one command</a></h2>
Go has some really nice tools for running tests and analyzing code. One of these functionalities is that you can generate coverage information when running tests, that can later be viewed in a browser using the go tool cover command. It turns out though, since doing it requires executing multiple commands after each other, it might be hard to remember the exact commands.
To this end, I created a bash alias that does everything in one command, gocov.
</div>

  
    <div class="post-card">

<h2><a href="/posts/static-copy-of-cms-website/">Creating a static copy of a Drupal, Wordpress or other CMS website</a></h2>
wget -P . -mpck --html-extension -e robots=off --wait 0.5 &lt;URL&gt; To understand the flags, you can check `man wget` of course, but some explanations follow here:
-P - Tell where to store the site -m - Create a mirror -p - Download all the required files (.css, .js) needed to properly render the page -c - Continue getting partially downloaded files -k - Convert links to enable local viewing --html-extension - Add the .
</div>

  
    <div class="post-card">

<h2><a href="/posts/pub-sub-with-zeromq-in-python/">Basic PUB/SUB connection with ZeroMQ in Python</a></h2>
First, to install ZeroMQ in python, use conda install pyzmq or pip install pyzmq depending on which python package manager you use.
The publisher (pub.py) import zmq import time ctx = zmq.Context() sock = ctx.socket(zmq.PUB) sock.bind(&#34;tcp://*:1234&#34;) print(&#34;Starting loop...&#34;) i = 1 while True: msg = &#34;Hi for the %d:th time...&#34; % i sock.send_string(msg) print(&#34;Sent string: %s ...&#34; % msg) i += 1 time.sleep(1) sock.close() ctx.term() The subscriber (sub.py) import zmq import time ctx = zmq.
</div>

  
    <div class="post-card">

<a href="/posts/table-driven-tests-in-csharp/"><img src="/posts/table-driven-tests-in-csharp//selection_0023.png" class="post-img-list"></a>

<h2><a href="/posts/table-driven-tests-in-csharp/">Table-driven tests in C#</a></h2>
Folks in the Go community have championed so called table-driven tests (see e.g. this post by Dave Cheney and the Go wiki) as a way to quickly and easily writing up a bunch of complete test cases with inputs and corresponding expected outputs, and looping over them to execute the function being tested. In short, the idea is to suggest a maximally short and convenient syntax to do this.
For example, given that we have a function like this in mylibrary.
</div>

  
    <div class="post-card">

<a href="/posts/scipipe-paper-published-in-gigascience/"><img src="/posts/scipipe-paper-published-in-gigascience//selection_999_198.png" class="post-img-list"></a>

<h2><a href="/posts/scipipe-paper-published-in-gigascience/">SciPipe paper published in GigaScience</a></h2>
We just wanted to share that the paper on our Go-based workflow library, SciPipe, was just published in GigaScience:
Abstract Background The complex nature of biological data has driven the development of specialized software tools. Scientific workflow management systems simplify the assembly of such tools into pipelines, assist with job automation, and aid reproducibility of analyses. Many contemporary workflow tools are specialized or not designed for highly complex workflows, such as with nested loops, dynamic scheduling, and parametrization, which is common in, e.
</div>

  
    <div class="post-card">

<a href="/posts/structured-go-routines-or-framework-less-flow-based-programming-in-go/"><img src="/posts/structured-go-routines-or-framework-less-flow-based-programming-in-go//selection_999_136.png" class="post-img-list"></a>

<h2><a href="/posts/structured-go-routines-or-framework-less-flow-based-programming-in-go/">Structured Go-routines or framework-less Flow-Based Programming in Go</a></h2>
I was so happy the other day to find someone else who found the great benefits of a little pattern for how to structure pipeline-heavy programs in Go, which I described in a few posts before. I have been surprised to not find more people using this kind of pattern, which has been so extremely helpful to us, so I thought to take this opportunity to re-iterate it again, in the hopes that more people might get aware of it.
</div>

  
    <div class="post-card">

<a href="/posts/linux-like-non-wsl-terminal-env-on-windows/"><img src="/posts/linux-like-non-wsl-terminal-env-on-windows//selection_029.png" class="post-img-list"></a>

<h2><a href="/posts/linux-like-non-wsl-terminal-env-on-windows/">Setting up a reasonable and light-weight Linux-like (non-WSL) terminal environment on Windows</a></h2>
I was looking for was a no-fuss, lightweight, robust and as simple as possible solution to running my normal Bash-based workflow inside the main Windows filesystem, interacting with the Windows world. Turns out there are some solutions. Read on for more info on that.
Windows Subsystem for Linux too heavy First, I must mention the impressive work by Microsoft on the Windows Subsystem for Linux (aka. WSL), which more or less lets you run an almost full-blown distribution of popular Linux distros like Ubuntu and Fedora.
</div>

  
    <div class="post-card">

<a href="/posts/linked-data-science/"><img src="/posts/linked-data-science//linkeddatascience.png" class="post-img-list"></a>

<h2><a href="/posts/linked-data-science/">Linked Data Science - For improved understandability of computer-aided research</a></h2>
This is an excerpt from the &quot;future outlook&quot; section of my thesis titled &quot;Reproducible Data Analysis in Drug Discovery with Scientific Workflows and the Semantic Web&quot; (click for the open access full text), which aims to provide various putative ways towards improved reproducibility, understandability and verifiability of computer-aided research.
Historically, something of a divide has developed between the metadata rich datasets and approaches in the world of Semantic Web/Ontologies/Linked Data, versus in the Big Data field in particular, which has been at least initially mostly focused on large unstructured datasets.
</div>

  
    <div class="post-card">

<a href="/posts/scipipe-preprint/"><img src="/posts/scipipe-preprint//selection_864.png" class="post-img-list"></a>

<h2><a href="/posts/scipipe-preprint/">Preprint on SciPipe - Go-based scientific workflow library</a></h2>
A pre-print for our Go-based workflow libarary SciPipe, is out, with the title SciPipe - A workflow library for agile development of complex and dynamic bioinformatics pipelines, co-authored by me and colleagues at pharmb.io: Martin Dahlö, Jonathan Alvarsson and Ola Spjuth. Access it here.
It has been more than three years since the first commit on the SciPipe Git repository in March, 2015, and development has been going in various degrees of intensity during these years, often besides other duties at pharmb.
</div>

  
    <div class="post-card">

<h2><a href="/posts/make-your-commandline-tool-workflow-friendly/">Make your commandline tool workflow friendly</a></h2>
There are a number of pitfalls that can make a commandline program really hard to integrate into a workflow (or &quot;pipeline&quot;) framework. The reason is that many workflow tools use output file paths to keep track of the state of the tasks producing these files. This is done for example to know which tasks are finished and can be skipped upon a re-run, and which are not.
To make the interaction between workflow tools and commandline programs as easy as possible, the tools should generally avoid overly clever ways of specifying them.
</div>

  
    <div class="post-card">

<a href="/posts/todournal/"><img src="/posts/todournal//journal_md_-_ptp_-_visual_studio_code_624-1.png" class="post-img-list"></a>

<h2><a href="/posts/todournal/">To make computational lab note-taking happen, make the journal into a todo-list (a &#34;Todournal&#34;)</a></h2>
Good lab note-taking is hard Good note-taking is in my opinion as important for computational research as for wet lab research. For computational research it is much easier though to forget doing it, since you might not have a physical notebook lying on your desk staring at you, but rather might need to open a specific software or file, to write the notes. I think this is one reason why lab note taking seems to happen a lot less among computational scientists than among wet lab ditto.
</div>

  
    <div class="post-card">

<a href="/posts/semantic-web-data-science-my-talk-at-linked-data-sweden-2018/"><img src="/posts/semantic-web-data-science-my-talk-at-linked-data-sweden-2018//selection_610.png" class="post-img-list"></a>

<h2><a href="/posts/semantic-web-data-science-my-talk-at-linked-data-sweden-2018/">Semantic Web ❤ Data Science? My talk at Linked Data Sweden 2018</a></h2>
During the last months, I have had the pleasure work together with Matthias Palmér (MetaSolutions AB) and Fernanda Dórea (National Veterinary Institute), to prepare for and organize this year's version of the annual Linked Data Sweden event, which this year was held in Uppsala hosted by the SciLifeLab Data Centre.
Thanks to engaged speakers and attendees, it turned into an interesting day with great discussions, new contacts, and a lot of new impressions and insights.
</div>

  
    <div class="post-card">

<h2><a href="/posts/parsing-drugbank-xml-or-any-large-xml-file-in-streaming-mode-in-go/">Parsing DrugBank XML (or any large XML file) in streaming mode in Go</a></h2>
While Go's XML stream-parsing support is great, the details of how to do that in a streaming fashion was not immediately clear from the docs, and I was thus saved by this blog post by David Singleton. Basically, you could use his blog post as a starting point, but I wanted to write up my own post to document some specifics and peculiarities I figured out.
Idea: Parse DrugBank XML to TSV So in short, we want to parse the DrugBank XML, which contains tons of hierarchical information about each drug in the dataset, and extract just a few fields, and output that into a nicely formatted tab-separated (.
</div>

  
    <div class="post-card">

<a href="/posts/equation-centric-dataflow-programming-in-go/"><img src="/posts/equation-centric-dataflow-programming-in-go//loan.gif" class="post-img-list"></a>

<h2><a href="/posts/equation-centric-dataflow-programming-in-go/">Equation-centric dataflow programming in Go</a></h2>
Mathematical notation and dataflow programming Even though computations done on computers are very often based on some type of math, it is striking that the notation used in math to express equations and relations is not always very readily converted into programming code. Outside of purely symbolic programming languages like sage math or the (proprietary) Wolfram language, there seem to always be quite a divide between the mathematical notation and the numerical implementation.
</div>

  
    <div class="post-card">

<a href="/posts/what-is-a-scientific-batch-workflow/"><img src="/posts/what-is-a-scientific-batch-workflow//dependencygraphnew_without_shadow-1.png" class="post-img-list"></a>

<h2><a href="/posts/what-is-a-scientific-batch-workflow/">What is a scientific (batch) workflow?</a></h2>
Workflows and DAGs - Confusion about the concepts Jörgen Brandt tweeted a comment that got me thinking again on something I've pondered a lot lately:
&quot;A workflow is a DAG.&quot; is really a weak definition. That's like saying &quot;A love letter is a sequence of characters.&quot; representation ≠ meaning\ @joergenbr
Jörgen makes a good point. A Directed Acyclic Graph (DAG) does not by any means capture the full semantic content included in a computational workflow.
</div>

  
    <div class="post-card">

<a href="/posts/golang-growing-in-bioinformatics-workflows/"><img src="/posts/golang-growing-in-bioinformatics-workflows//gopher_thinking_workflows.png" class="post-img-list"></a>

<h2><a href="/posts/golang-growing-in-bioinformatics-workflows/">Go is growing in bioinformatics workflow tools</a></h2>
TL;DR: We wrote a post on gopherdata.io, about the growing ecosystem of Go-based workflow tools in bioinformatics. Go read it here
It is interesting to note how Google's Go programming language seems to increase in popularity in bioinformatics.
Just to give a sample of some of the Go based bioinformatics tools I've stumbled upon, there is since a few years back, the biogo library, providing common functionality for bioinformatics tasks.
</div>

  
    <div class="post-card">

<h2><a href="/posts/my-frustration-with-the-state-of-note-taking-tools/">The frustrating state of note taking tools</a></h2>
As I'm constantly digging into a wide variety of topics, reading, thinking, and also trying to memorize a bit, it sometimes seems paper might not completely cut it - primarily since paper is not searchable. As the collection of notes grow, it also becomes unprohibitive to lug around piles of paper-notebooks just to have them handy when needing to check something up.
What I've been doing so far is to combine paper-based notebooks for thinking and developing ideas, with a markdown based solution, for keeping a daily journal, as well as having a folder of such markdown files organized more according to topic, remotely like a wiki.
</div>

  
    <div class="post-card">

<a href="/posts/how-to-learn/"><img src="/posts/how-to-learn//amfn.jpg" class="post-img-list"></a>

<h2><a href="/posts/how-to-learn/">Learning how to learn</a></h2>
I'm reading A mind for numbers, by Barbara Oakley. Firstly, it is a very interesting book, but the main lesson I've already learned from this book seems so paramount that I have to write it down, so I don't forget it (some meta-connotations in that statement ;) ). I found the book through Barbara's coursera course &quot;Learning how to Learn&quot;, and to me it seems learning in general is the topic of the book too, more than numbers specifically - but I still have to read it through, so stay tuned.
</div>

  
    <div class="post-card">

<h2><a href="/posts/provenance-reports-in-scientific-workflows/">On Provenance Reports in Scientific Workflows</a></h2>
One of the more important tasks for a scientific workflow is to keep track of so called &quot;provenance information&quot; about its data outputs - information about how each data file was created. This is important so other researchers can easily replicate the study (re-run it with the same software and tools). It should also help for anyone wanting to reproduce it (re-run the same study design, possibly with other software and tools).
</div>

  
    <div class="post-card">

<h2><a href="/posts/range-over-multiple-go-channels/">(Almost) ranging over multiple Go channels simultaneously</a></h2>
Thus, optimally, one would want to use Go's handy range keyword for looping over multiple channels, since range takes care of closing the for-loop at the right time (when the inbound channel is closed). So something like this (N.B: non-working code!):
for a, b, c := range chA, chB, chC { doSomething(a, b, c) } Unfortunately this is not possible, and probably for good reason (how would it know whether to close the loop when the first, or all of the channels are closed?
</div>

  
    <div class="post-card">

<a href="/posts/first-production-workflow-run-with-scipipe/"><img src="/posts/first-production-workflow-run-with-scipipe//terminal_411.png" class="post-img-list"></a>

<h2><a href="/posts/first-production-workflow-run-with-scipipe/">First production run with SciPipe - A Go-based scientific workflow tool</a></h2>
Today marked the day when we ran the very first production workflow with SciPipe, the Go-based scientific workflow tool we've been working on over the last couple of years. Yay! :)
This is how it looked (no fancy GUI or such yet, sorry):
The first result we got in this very very first job was a list of counts of ligands (chemical compounds) in the ExcapeDB dataset (download here) interacting with the 44 protein/gene targets identified by Bowes et al as a good baseline set for identifying hazardous side-effects effects in the body (that is, any chemical compounds binding these proteins, will never become an approved drug).
</div>

  
    <div class="post-card">

<h2><a href="/posts/compiling-rdfhdt-c-tools-on-uppmax-rhel-centos-7/">Compiling RDFHDT C&#43;&#43; tools on UPPMAX (RHEL/CentOS 7)</a></h2>
At pharmb.io we are researching how to use semantic technologies to push the boundaries for what can be done with intelligent data processing, often of large datasets (see e.g. our paper on linking RDF to cheminformatics and proteomics, and our work on the RDFIO software suite). Thus, for us, RDFHDT opens new possibilites. As we are heavy users of the UPPMAX HPC center for our computations, and so, we need to have the HDT tools available there.
</div>

  
    <div class="post-card">

<a href="/posts/new-paper-on-rdfio-for-interoperable-biomedical-datamanagement-in-semantic-mediawiki/"><img src="/posts/new-paper-on-rdfio-for-interoperable-biomedical-datamanagement-in-semantic-mediawiki//selection_388-1.png" class="post-img-list"></a>

<h2><a href="/posts/new-paper-on-rdfio-for-interoperable-biomedical-datamanagement-in-semantic-mediawiki/">New paper on RDFIO for interoperable biomedical data management in Semantic MediaWiki</a></h2>
As my collaborator and M.Sc. supervisor Egon Willighagen already blogged, we just released a paper titled: &quot;RDFIO: extending Semantic MediaWiki for interoperable biomedical data management&quot;, with uses cases from Egon and Pekka Kohonen, coding help from Ali King and project supervision from Denny Vrandečić, Roland Grafström and Ola Spjuth.
See the picture below (from the paper) for an overview of all the newly developed functionality (drawn in black), as related to the previously existing functionality (drawn in grey):
</div>

  
    <div class="post-card">

<a href="/posts/launching-kubernetes-jobs-from-the-go-api-notes-from-a-beginner/"><img src="/posts/launching-kubernetes-jobs-from-the-go-api-notes-from-a-beginner//selection_117.png" class="post-img-list"></a>

<h2><a href="/posts/launching-kubernetes-jobs-from-the-go-api-notes-from-a-beginner/">Notes on launching kubernetes jobs from the Go API</a></h2>
This post is also published on medium
My current work at pharmb.io entails adding kubernetes support to my light-weight Go-based scientific workflow engine, scipipe (kubernetes, or k8s for short, is Google&rsquo;s open source project for orchestrating container based compute clusters), which should take scipipe from a simple &ldquo;run it on your laptop&rdquo; workflow system with HPC support still in the work, to something that can power scientific workflows on any set of networked computers that can run kubernetes, which is quite a few (AWS, GCE, Azure, your Raspberry Phi cluster etc etc).
</div>

  
    <div class="post-card">

<a href="/posts/smwcon-fall-2016/"><img src="/posts/smwcon-fall-2016//smwcon_intro.jpg" class="post-img-list"></a>

<h2><a href="/posts/smwcon-fall-2016/">SMWCon Fall 2016 - My talk on large RDF imports</a></h2>
[I was invited to give a talk at ]Semantic MediaWiki (SMW) conference[ (SMWCon) in Frankfurt last week, on our work on enabling import of RDF datasets into ]SMW[. I have presented at SMWCon before as well (2011: ]blog[, ]slides[, ]video[, 2013: ]slides[), so it was nice to re-connect with some old friends, and to get up to date about how SMW is developing, as well as share about our own contributions.
</div>

  
    <div class="post-card">

<a href="/posts/luigi-tutorial/"><img src="/posts/luigi-tutorial//luigi_screenshot.png" class="post-img-list"></a>

<h2><a href="/posts/luigi-tutorial/">Tutorial: Luigi for Scientific Workflows</a></h2>
This is a Luigi tutorial I held at the e-Infrastructures for Massively parallel sequencing workshop (Video archive) at SciLifeLab Uppsala in January 2015, moved here for future reference.
What is Luigi? Luigi is a batch workflow system written in Python and developed by Erik Bernhardson and others at Spotify, where it is used to compute machine-learning powered music recommendation lists, top lists etc.
Luigi is one of not-too-many batch workflow systems that supports running both normal command line jobs and Hadoop jobs in the same (in this tutorial, we will focus only on the command line part).
</div>

  
    <div class="post-card">

<h2><a href="/posts/the-best-of-go-d-and-rust/">Combining the best of Go, D and Rust?</a></h2>
I've been following the development of D, Go and Rust (and also FreePascal for some use cases) for some years (been into some benchmarking for bioinfo tasks), and now we finally have three (four, with fpc) stable statically compiled languages with some momentum behind them, meaning they all are past 1.0.
While I have went with Go for current projects, I still have a hard time &quot;totally falling in love&quot; with any single of these languages.
</div>

  
    <div class="post-card">

<a href="/posts/time-boxing-and-unified-trello-board/"><img src="/posts/time-boxing-and-unified-trello-board//selection_039.png" class="post-img-list"></a>

<h2><a href="/posts/time-boxing-and-unified-trello-board/">Time-boxing and a unified trello board = productivity</a></h2>
Figure: Sketchy screenshot of how my current board looks. Notice especially the &quot;Now&quot; stack, marked in yellow, where you are only allowed to put one single card.
I used to have a very hard time getting an overview of my current work, and prioritizing and concentrating on any single task for too long. I always felt there might be something else that might be more important than what I were currently doing.
</div>

  
    <div class="post-card">

<a href="/posts/the-unexpected-usefullness-of-json-on-the-commandline/"><img src="/posts/the-unexpected-usefullness-of-json-on-the-commandline//json_vector_logo_svg.png" class="post-img-list"></a>

<h2><a href="/posts/the-unexpected-usefullness-of-json-on-the-commandline/">The unexpected convenience of JSON on the commandline</a></h2>
I was working with a migration from drupal to processwire CMS:es, where I wanted to be able to pipe data, including the body field with HTML formatting and all, through multiple processing steps in a flexible manner. I'd start with an extraction SQL query, through a few components to replace and massage the data, and finally over to an import command using processwire's wireshell tool. So, basically I needed a flexible format for structured data that could be sent as one &quot;data object&quot; per line, to work nicely with linux commandline tools like grep, sed and awk.
</div>

  
    <div class="post-card">

<a href="/posts/matrix-transformation-as-model-for-data-flow-operations/"><img src="/posts/matrix-transformation-as-model-for-data-flow-operations//matrix01.png" class="post-img-list"></a>

<h2><a href="/posts/matrix-transformation-as-model-for-data-flow-operations/">The matrix transformation as a model for declarative atomic data flow operations</a></h2>
After just reading on Hacker News about Google's newly released TensorFlow library, for deep learning based on tensors and data flow, I realized I wrote in a draft post back in 2013 that:
&quot;What if one could have a fully declarative &ldquo;matrix language&rdquo; in which all data transformations ever needed could be declaratively defined in a way that is very easy to comprehend?&quot;
... so, I thought this is a good time to post this draft, to see whether it spurs any further ideas.
</div>

  
    <div class="post-card">

<a href="/posts/dynamic-workflow-scheduling/"><img src="/posts/dynamic-workflow-scheduling//scheduling_unsplash-1.jpg" class="post-img-list"></a>

<h2><a href="/posts/dynamic-workflow-scheduling/">Wanted: Dynamic workflow scheduling</a></h2>
Photo credits: Matthew Smith / Unsplash
In our work on automating machine learning computations in cheminformatics with scientific workflow tools, we have came to realize something; Dynamic scheduling in scientific workflow tools is very important and sometimes badly needed.
What I mean is that new tasks should be able to be scheduled during the execution of a workflow, not just in its scheduling phase.
What is striking is that far from all workflow tools allow this.
</div>

  
    <div class="post-card">

<a href="/posts/how-to-be-productive-in-vim-in-30-minutes/"><img src="/posts/how-to-be-productive-in-vim-in-30-minutes//selection_333-1.png" class="post-img-list"></a>

<h2><a href="/posts/how-to-be-productive-in-vim-in-30-minutes/">How to be productive in vim in 30 minutes</a></h2>
I had heard a lot of people say vim is very hard to learn, and got the impression that it will take a great investment to switch to using it.
While I have came to understand that they are right in that there is a lot of things to invest in to get really great at using vim, that will really pay back, I have also found out one thing that I see almost no-one mentioning:
</div>

  
    <div class="post-card">

<h2><a href="/posts/how-to-compile-tmux-2.0-on-rhel6-sl6/">How to compile tmux 2.0 on RHEL6 / SL6 to get zoomable panes</a></h2>
 
</div>

  
    <div class="post-card">

<h2><a href="/posts/how-to-compile-vim-for-use-with-pyenv-and-vim-pyenv/">How to compile vim for use with pyenv and vim-pyenv</a></h2>
This manifested itself in a bunch of error message from the python module in vim, ending with:
AttributeError: &#39;module&#39; object has no attribute &#39;vars&#39; I first thought it was an error in vim-pyenv and reported it (see that issue for more in-depth details). In summary it turns out that older versions of VIM indeed lack some attributes in its python module, so I figured I had to compile my own version, below are just my notes about how to do this, for future reference:
</div>

  
    <div class="post-card">

<a href="/posts/how-i-would-like-to-write-golang/"><img src="/posts/how-i-would-like-to-write-golang//selection_301.png" class="post-img-list"></a>

<h2><a href="/posts/how-i-would-like-to-write-golang/">How I would like to write Go programs</a></h2>
Some time ago I got a post published on GopherAcademy, outlining in detail how I think a flow-based programming inspired syntax can strongly help to create clearer, easier-to-maintain, and more declarative Go programs.
These ideas have since became clearer, and we (Ola Spjuth's research group at pharmbio) have successfully used them to make the workflow syntax for Luigi (Spotify's great workflow engine by Erik Bernhardsson &amp; co) workflows easier, as implemented in the SciLuigi helper library.
</div>

  
    <div class="post-card">

<a href="/posts/terminator-middle-way/"><img src="/posts/terminator-middle-way//samuel_milou2--proj-b2013262-nobackup-workflows-workflows_296-1.png" class="post-img-list"></a>

<h2><a href="/posts/terminator-middle-way/">Terminator as a middle-way between floating and tiling window managers</a></h2>
I have tried hard to improve my linux desktop productivity by learning to do as much as possible using keyboard shortcuts, aliases for terminal commands etc etc (I even produced an online course on linux commandline productivity).
In this spirit, I naturally tried out a so called tiling window manager (aka tiling wm). In short, a tiling wm organizes all open windows on the screen (or on the current desktop) into a &quot;tiled&quot; grid of frames.
</div>

  
    <div class="post-card">

<a href="/posts/fbp-data-flow-syntax/"><img src="/posts/fbp-data-flow-syntax//selection_288.png" class="post-img-list"></a>

<h2><a href="/posts/fbp-data-flow-syntax/">FBP inspired data flow syntax: The missing piece for the success of functional programming?</a></h2>
Often when I suggest people have a look at Flow-based Programming (FBP) or Data Flow for one reason or another, people are often put off by the strong connection between these concepts and graphical programming. That is, the idea that programs will be easier to understand if expressed and developed in a visual notation.
This is unfortunate, since I think this is in no way the core benefit of FBP or Data Flow, although it is a nice side-effect for those who prefer it.
</div>

  
    <div class="post-card">

<a href="/posts/organizing-compbio-projects/"><img src="/posts/organizing-compbio-projects//-bin-bash_251.png" class="post-img-list"></a>

<h2><a href="/posts/organizing-compbio-projects/">A few thoughts on organizing computational (biology) projects</a></h2>
I read this excellent article with practical recommendations on how to organize a computational project, in terms of directory structure.
Directory structure matters The importance of a good directory structure seems to often be overlooked in teaching about computational biology, but can be the difference between a successful project, and one where every change or re-run of some part of a workflow, will require days of manual fiddling to get hand on the right data, in the right format, in the right place, with the right version of the workflow, with the right parameters, and then succeed to run it without errors.
</div>

  
    <div class="post-card">

<a href="/posts/flowbased-vs-erlang-message-passing/"><img src="/posts/flowbased-vs-erlang-message-passing//elixir-pipeline-parallellism-crop.jpg" class="post-img-list"></a>

<h2><a href="/posts/flowbased-vs-erlang-message-passing/">Flow-based programming and Erlang style message passing - A Biology-inspired idea of how they fit together</a></h2>
I think Erlang/Elixir fits great as control plane or service-to-service messaging layer for distributing services built with flow-based programming
Just back from a one day visit to Erlang User Conference. I find the Erlang virtual machine fascinating. And with the new Elixir language built on top of it to fix some of the pain points with Erlang the language, the eco-system has got even more interesting.
What I find exciting about Erlang/Elixir and its virtual machine, is its ability to utilize multiple CPU:s on computers, and doing this across multiple computers, in what is commonly referred to as &quot;distributed computing&quot;.
</div>

  
    <div class="post-card">

<a href="/posts/irods-rulelang-cheatsheet/"><img src="/posts/irods-rulelang-cheatsheet//irodsrules_p1.png" class="post-img-list"></a>

<h2><a href="/posts/irods-rulelang-cheatsheet/">A cheatsheet for the iRODS rule language</a></h2>
iRODS, the &quot;integrated rule oriented data system&quot; is a super cool system for managing datasets consisting of files, from smallish ones, to really large ones counted in petabytes, and possibly spanning multiple continents.
There's a lot to be said about iRODS (up for another blog post) but the one most interesting feature, in my opinion, is the rule language, which allows to define custom rules and policies for how data should be handled, totally automatically, depending on a lot of factors.
</div>

  
    <div class="post-card">

<a href="/posts/workflows-dataflow-not-task-deps/"><img src="/posts/workflows-dataflow-not-task-deps//peptide_workflow.png" class="post-img-list"></a>

<h2><a href="/posts/workflows-dataflow-not-task-deps/">Workflow tool makers: Allow defining data flow, not just task dependencies</a></h2>
Upsurge in workflow tools There seem to be a little upsurge in light-weight - often python-based - workflow tools for data pipelines in the last couple of years: Spotify's Luigi, OpenStack's Mistral, Pinterest's Pinball, and recently AirBnb's Airflow, to name a few. These are all interesting tools, and it is an interesting trend for us at pharmbio, who try to see how we can use workflow tools to automate bio- and cheminformatics tasks on compute clusters.
</div>

  
    <div class="post-card">

<a href="/posts/patterns-for-composable-concurrent-pipelines-in-go/"><img src="/posts/patterns-for-composable-concurrent-pipelines-in-go//selection_212.png" class="post-img-list"></a>

<h2><a href="/posts/patterns-for-composable-concurrent-pipelines-in-go/">Patterns for composable concurrent pipelines in Go</a></h2>
I realize I didn't have a link to my blog on Gopher Academy, on patterns for compoasable concurrent pipelines in Go(lang), so here it goes:
blog.gopheracademy.com/composable-pipelines-pattern 
</div>

  
    <div class="post-card">

<a href="/posts/the-role-of-simplicity-in-testing-and-automation/"><img src="/posts/the-role-of-simplicity-in-testing-and-automation//automation.png" class="post-img-list"></a>

<h2><a href="/posts/the-role-of-simplicity-in-testing-and-automation/">The role of simplicity in testing and automation</a></h2>
Disclaimer: Don't take this too seriously ... this is &quot;thinking-in-progress&quot; :)
It just struck me the other minute, how simplicity is the key theme behind two very important areas in software development, that I've been dabbling with quite a bit recently: Testing, and automation.
Have you thought about how testing, in its essence, is: Wrapping complex code, which you can't mentally comprehend completely, in simple code, that you can mentally comprehend, at least one test at a time.
</div>

  
    <div class="post-card">

<a href="/posts/the-problem-with-make-for-scientific-workflows/"><img src="/posts/the-problem-with-make-for-scientific-workflows//selection_131.png" class="post-img-list"></a>

<h2><a href="/posts/the-problem-with-make-for-scientific-workflows/">The problem with make for scientific workflows</a></h2>
The workflow problem solved once and for all in 1979? As soon as the topic of scientific workflows is brought up, there are always a few make fans fervently insisting that the problem of workflows is solved once and for all with GNU make, written first in the 70's :)
Personally I haven't been so sure. On the one hand, I know the tool solves a lot of problems for many people.
</div>

  
    <div class="post-card">

<a href="/posts/dynamic-navigation-for-higher-performance/"><img src="/posts/dynamic-navigation-for-higher-performance//01_truck_combination_with_trip_1_bmp.png" class="post-img-list"></a>

<h2><a href="/posts/dynamic-navigation-for-higher-performance/">Dynamic Navigation for Higher Performance</a></h2>
Improving performance in Delphi Bold MDA applications by replacing navigation code with derived links in the model This post on Model Driven Architecture in Delphi and Bold, by Rolf Lampa, has been previously published on howtodothings.com.
Modeling class structures takes some thinking, and when done the thinking and the drawing and after that starting up using the model, then you'll spend awful lots of code traversing links in order to retrieve trivial info in a given object structure.
</div>

  
    <div class="post-card">

<a href="/posts/ngs-bioinformatics-intro-course-day-3/"><img src="/posts/ngs-bioinformatics-intro-course-day-3//ngsintro-coding.jpg" class="post-img-list"></a>

<h2><a href="/posts/ngs-bioinformatics-intro-course-day-3/">NGS Bioinformatics Course Day 3: New Luigi helper tool, &#34;real-world&#34; NGS pipelines</a></h2>
It turned out I didn't have the time and strength to blog every day at the NGS Bioinformatics Intro course, so here comes a wrap up with some random notes and tidbits from the last days, including any concluding remarks!
These days we started working on a more realistic NGS pipeline, on analysing re-sequencing samples (slides, tutorial).
First some outcome from this tutorial What do I mean with &quot;outcome&quot;? Well, as I tried to manually copy and paste the bag of hairy nasty long bash commandline strings in the tutorial pages, that all depended upon each other, I got so frustrated that I decided to try to encode them in a workflow language / tool.
</div>

  
    <div class="post-card">

<h2><a href="/posts/hadoop-ngs-workshop/">Random links from the Hadoop NGS Workshop</a></h2>
 Spark notebook Scala notebook ADAM By Big Data Genomics Tweet by Frank Nothaft on common workflow def Part of Global Alliance for ... Another link is ga4gh.org Tachyon in-memory file system Cuneiform Does support multiple outputs etc Black-box vs. White-box Workflow dependency graph can be dynamically built up while you're running Can specity tasks in any scripting languages, or in cuneiform itself Hi-Way Worklow engine for Hadoop​ Can run exported Galaxy workflows 
</div>

  
    <div class="post-card">

<a href="/posts/our-experiences-using-spotifys-luigi-for-bioinformatics-workflows/"><img src="/posts/our-experiences-using-spotifys-luigi-for-bioinformatics-workflows//selection_047_luigi.png" class="post-img-list"></a>

<h2><a href="/posts/our-experiences-using-spotifys-luigi-for-bioinformatics-workflows/">Links: Our experiences using Spotify&#39;s Luigi for Bioinformatics Workflows</a></h2>
Fig 1: A screenshot of Luigi's web UI, of a real-world (although rather simple) workflow implemented in Luigi:
Update May 5, 2016: Most of the below material is more or less outdated. Our latest work has resulted in the SciLuigi helper library, which we have used in production and will be focus of further developments.
In the Bioclipse / Pharmaceutical Bioinformatics group at Dept of Pharm. Biosciences att UU, we are quite heavy users of Spotify's Luigi workflow library, to automate workflows, mainly doing Machine Learning heavy lifting.
</div>

  
    <div class="post-card">

<a href="/posts/ngs-bioinformatics-intro-course-day-2/"><img src="/posts/ngs-bioinformatics-intro-course-day-2//4130_mini_ion_lab-copy.png" class="post-img-list"></a>

<h2><a href="/posts/ngs-bioinformatics-intro-course-day-2/">NGS Bioinformatics Intro Course Day 2</a></h2>
Today was the second day of the introductory course in NGS bioinformatics that I'm taking as part of my PhD studies.
For me it started with a substantial oversleep, probably due to a combination of an annoying cold and the ~2 hour commute from south Stockholm to Uppsala and BMC. Thus I missed some really interesting material (and tutorial) on file types in NGS analysis, but will make sure to go through that in my free time during the week.
</div>

  
    <div class="post-card">

<a href="/posts/ngs-intro-course-day-1/"><img src="/posts/ngs-intro-course-day-1//ngsintro.jpg" class="post-img-list"></a>

<h2><a href="/posts/ngs-intro-course-day-1/">NGS Bioinformatics Intro Course Day 1</a></h2>
Just finished day 1 of the introductory course on Bioinformatics for Next generation sequencing data at Scilifelab Uppsala. Attaching a photo from one of the hands-on tutorial sessions, with the tutorial leaders, standing to the right.
Today's content was mostly introductions to the linux commandline in general, and the UPPMAX HPC environment in particular, an area I'm already very familiar with, after two years as a sysadmin at UPPMAX. Thus, today I mostly got to help out the other students a bit.
</div>

  
    <div class="post-card">

<h2><a href="/posts/introductory-course-in-bioinformatics-for-ngs-data/">Taking a one week introductory course in Bioinformatics for NGS data</a></h2>
Right now I'm sitting on the train and trying to get my head around some of the pre-course materials.
</div>

  
    <div class="post-card">

<h2><a href="/posts/rdfio-vm/">RDFIO VM</a></h2>
 The old Virtual Machine still available The old virtual machine from June 25, 2014, based on Ubuntu 14.04, and RDFIO 2.x can be found here 
</div>

  
    <div class="post-card">

<h2><a href="/posts/smallest-pipeable-go-program/">The smallest pipeable go program</a></h2>
import ( &ldquo;io&rdquo; &ldquo;os&rdquo; )
func main() { io.Copy(os.Stdout, os.Stdin) }
\... or (credits: [Roger Peppe](https://twitter.com/rogpeppe)): ```go package main import ( &#34;bufio&#34; &#34;fmt&#34; &#34;os&#34; ) func main() { for scan := bufio.NewScanner(os.Stdin); scan.Scan(); { fmt.Printf(&#34;%s\n&#34;, scan.Text()) } } Ah, I just realized that the &quot;smallest pipeable&quot; Go(lang) program is rather small, if using my little library of minimalistic streaming components. Nothing more than:
package main import ( &#34;fmt&#34; &#34;github.com/samuell/glow&#34; ) func main() { inchan := make(chan []byte, 16) glow.
</div>

  
    <div class="post-card">

<a href="/posts/profiling-and-call-graphs-for-golang/"><img src="/posts/profiling-and-call-graphs-for-golang//basecompl_blow_callgraph_crop.png" class="post-img-list"></a>

<h2><a href="/posts/profiling-and-call-graphs-for-golang/">Profiling and creating call graphs for Go programs</a></h2>
In trying to get my head around the code of the very interesting GoFlow library, (for flow-based programming in Go), and the accompanying flow-based bioinformatics library I started hacking on, I needed to get some kind of visualization (like a call graph) ... something like this:
(And in the end, that is what I got ... read on ... ) :)
I then found out about the go tool pprof command, for which the Go team published a blog post on here.
</div>

  
    <div class="post-card">

<a href="/posts/ebnf-parser-for-galaxy-toolconfig-syntax-with-antlr/"><img src="/posts/ebnf-parser-for-galaxy-toolconfig-syntax-with-antlr//screenshot-antlrworks_1_4_2.png" class="post-img-list"></a>

<h2><a href="/posts/ebnf-parser-for-galaxy-toolconfig-syntax-with-antlr/">(E)BNF parser for parts of the Galaxy ToolConfig syntax with ANTLR</a></h2>
As blogged earlier, I'm currently into parsing the syntax of some definitions for the parameters and stuff of command line tools. As said in the linked blog post, I was pondering whether to use the Galaxy Toolconfig format or the DocBook CmdSynopsis format. It turned out though Well, that cmdsynopsis lacks the option to specify a list of valid choices, for a parameter, as is possible in the Galaxy ToolConfig format (see here), and thus can be used to generate drop-down lists in wizards etc.
</div>

  
    <div class="post-card">

<h2><a href="/posts/galaxy-toolconfig-to-docbook-cmdsynopsis/">Partial Galaxy ToolConfig to DocBook CmdSynopsis conversion with XSLT RegEx</a></h2>
&lt;tool id=&#34;sam_to_bam&#34; name=&#34;SAM-to-BAM&#34; version=&#34;1.1.1&#34;&gt; &lt;description&gt;converts SAM format to BAM format&lt;/description&gt; &lt;requirements&gt; &lt;requirement type=&#34;package&#34;&gt;samtools&lt;/requirement&gt; &lt;/requirements&gt; &lt;command interpreter=&#34;python&#34;&gt; sam_to_bam.py --input1=$source.input1 --dbkey=${input1.metadata.dbkey} #if $source.index_source == &#34;history&#34;: --ref_file=$source.ref_file #else --ref_file=&#34;None&#34; #end if --output1=$output1 --index_dir=${GALAXY_DATA_INDEX_DIR} &lt;/command&gt; &lt;inputs&gt; &lt;conditional name=&#34;source&#34;&gt; &lt;param name=&#34;index_source&#34; type=&#34;select&#34; label=&#34;Choose the source for the reference list&#34;&gt; &lt;option value=&#34;cached&#34;&gt;Locally cached&lt;/option&gt; &lt;option value=&#34;history&#34;&gt;History&lt;/option&gt; &lt;/param&gt; &lt;when value=&#34;cached&#34;&gt; &lt;param name=&#34;input1&#34; type=&#34;data&#34; format=&#34;sam&#34; label=&#34;SAM File to Convert&#34;&gt; &lt;validator type=&#34;unspecified_build&#34; /&gt; &lt;validator type=&#34;dataset_metadata_in_file&#34; filename=&#34;sam_fa_indices.loc&#34; metadata_name=&#34;dbkey&#34; metadata_column=&#34;1&#34; message=&#34;Sequences are not currently available for the specified build.
</div>

  
    <div class="post-card">

<h2><a href="/posts/answering-questions-by-wrapping-simulations-in-semantics/">Answering questions without answers - by wrapping simulations in semantics</a></h2>
There are lots of things that can't be answered by a computer from data alone. Maybe the majority of what we humans perceive as knowledge is inferred from a combination of data (simple fact statements about reality) and rules that tell how facts can be combined together to allow making implicit knowledge (knowledge that is not persisted as facts anywhere, but has to be inferred from other facts and rules) become explicit.
</div>

  
    <div class="post-card">

<h2><a href="/posts/a-hello-world-prolog-program/">A &#34;Hello World&#34; program in SWI-Prolog</a></h2>
Then you can load the program from inside prolog after you've started it.
So, let's start the prolog interactive GUI:
prolog Then, in the Prolog GUI, load the file test.pl like so:
?- [test]. Now, if you had some prolog clauses in the test.pl file, you will be able to extract that information by querying.
A very simple test program that you could create is:
/* Some facts about parent relationships */ parent(sam,mark).
</div>

  

  </main>
  <footer>
    <p>Copyright &copy; 2024 Living Systems. All rights reserved.</p>

  </footer>
</body>
</html>
