<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width">
<title>Tutorial: Luigi for Scientific Workflows | Living Systems</title>

    <link rel="stylesheet" href="/css/main.css">


      <script src="/js/main.js"></script>


</head>
<body>
  <header>
    <h1>Living Systems</h1>

  <nav>
    <ul>
    <li>
      <a href="/">Home</a>
    </li>
    <li>
      <a aria-current="true" class="ancestor" href="/posts/">Posts</a>
    </li>
    <li>
      <a href="/tags/">Tags</a>
    </li>
    </ul>
  </nav>


  </header>
  <main>
    
  <h1>Tutorial: Luigi for Scientific Workflows</h1>

  <img src="luigi_screenshot.png">

  
  
  <time datetime="2016-06-21T13:49:00&#43;02:00">June 21, 2016</time>

  <p><em>This is a Luigi tutorial I held at the <a href="http://uppnex.se/events/eInfraMPS2015/">e-Infrastructures for Massively
parallel sequencing</a> workshop
(<a href="https://www.youtube.com/channel/UCfLDx5VYn25QIZLmtybvdeQ/videos">Video
archive</a>)
at <a href="http://scilifelab.se/">SciLifeLab</a> Uppsala in January 2015, moved
here for future reference.</em></p>
<h2 id="siteassetsfiles1068luigi_screenshot480x0-ispng"><img src="/site/assets/files/1068/luigi_screenshot.480x0-is.png" alt=""></h2>
<h2 id="what-is-luigi">What is Luigi?</h2>
<p><a href="https://github.com/spotify/luigi">Luigi</a> is a batch workflow system
written in Python and developed by <a href="https://erikbern.com/">Erik
Bernhardson</a> and others at
<a href="http://spotify.com/">Spotify</a>, where it is used to compute
machine-learning powered music recommendation lists, top lists etc.</p>
<p>Luigi is one of not-too-many batch workflow systems that supports
running both normal command line jobs and
<a href="http://hadoop.apache.org/">Hadoop</a> jobs in the same (in this tutorial,
we will focus only on the command line part).</p>
<p>Luigi workflows are developed in an object oriented fashion in python
code, and are executed and controlled from the commandline. But when
running, the status of the workflow run can be followed in a web
browser, in the graphical web interface that luigi ships with (as
demonstrated in the picture above).</p>
<p>Luigi is a little special compared to most other workflow solutions,
that the dependency graph is by default defined by hard-coding the
upstream dependent task, inside each task. In this regard, luigi tasks
are quite similar to functions in functional programming, where each
function knows everything needed to provide it's answer, including all
the other functions that need to be executed to get there.</p>
<p>There are ways to override these hard-coded dependencies, to create
other workflows though, but since workflows in bioinformatics often need
more flexibility than that, and need to be easy to augment with e.g.
extra filtering steps anywhere in a workflow, we will in this tutorial
show how we can extend the &quot;functional&quot; design of luigi, into a more
&quot;data flow&quot; like design that most other workflow engines follow.</p>
<h2 id="some-useful-resources">Some useful resources</h2>
<ul>
<li><a href="https://github.com/pharmbio/sciluigi">The SciLuigi helper library</a></li>
<li><a href="http://luigi.readthedocs.org/en/latest/">Official luigi
documentation</a></li>
<li><a href="https://github.com/spotify/luigi">Luigi project (source code and issue tracker) on
Github</a></li>
<li><a href="https://groups.google.com/forum/#!forum/luigi-user">Luigi users mailing list / Google
group</a></li>
<li><a href="https://www.youtube.com/watch?v=Wgqkc7f13co">A talk on Luigi by Luigi creator Erik
Bernhardson</a></li>
</ul>
<h2 id="tutorial-table-of-contents">Tutorial: â€‹Table of contents</h2>
<p>The tutorial is divided into the following sections:</p>
<ul>
<li><a href="#install">Installing Luigi</a></li>
<li><a href="#helloworld">Defining workflows in Luigi / Hello World</a></li>
<li><a href="#dependencies_parameters">Adding dependencies and parameters</a></li>
<li><a href="#visualize">Visualizing running workflows</a> (optional)</li>
<li><a href="#reuse">Re-using components in multiple workflows</a></li>
<li><a href="#multi_input_output">A solution for multiple inputs and outputs</a></li>
<li><a href="#commands">Executing commands</a></li>
</ul>
<p><em><strong>UPDATE June 21, 2016:</strong> Note that the strategy used in points 5-7
above have been collected into the</em> <a href="https://github.com/pharmbio/sciluigi">SciLuigi helper
library</a><em>, which is highly
recommended for bioinformatics use cases</em>!</p>
<p>[]{#install}<strong>Installing Luigi</strong></p>
<p><strong>1. Install the pyenv python version handler</strong></p>
<pre><code>lang-bash
git clone git://github.com/yyuu/pyenv.git ~/.pyenv
</code></pre>
<p>Make pyenv start every time you log in:</p>
<pre><code>lang-bash
echo 'export PYENV_ROOT=&quot;$HOME/.pyenv&quot;' &gt;&gt; ~/.bash_profile
echo 'export PATH=&quot;$PYENV_ROOT/bin:$PATH&quot;' &gt;&gt; ~/.bash_profile
echo 'eval &quot;$(pyenv init -)&quot;' &gt;&gt; ~/.bash_profile
</code></pre>
<p><strong>Important!</strong> Reload the bash profile file to enable the new settings:</p>
<pre><code>lang-bash
source ~/.bash_profile
</code></pre>
<p><strong>2. Install your own python (version)</strong></p>
<p>Get pyenv to install the python version of your liking.</p>
<pre><code>lang-bash
pyenv install 2.7.6
</code></pre>
<p>Make the version you just installed to the standard version for every
time you run python.</p>
<pre><code>lang-bash
pyenv global 2.7.6
</code></pre>
<p><strong>3. Install luigi and its dependencies</strong></p>
<p>Install the tornado library, which is used in the communication between
the luigi scheduler daemon and individual workers:</p>
<pre><code>lang-bash
pip install tornado
</code></pre>
<p>Install luigi itself:</p>
<pre><code>lang-bash
pip install luigi
</code></pre>
<p>Re-load your ~/.bash_profile, so that the right binaries (such as
luigid) are used:</p>
<pre><code>lang-bash
source ~/.bash_profile
</code></pre>
<h2 id="helloworlddefining-workflows-in-luigi--hello-world">[]{#helloworld}Defining workflows in Luigi / Hello World</h2>
<h3 id="luigi-basics">Luigi basics</h3>
<p>Luigi workflows consists more or less of tasks and targets.</p>
<p>Targets are some sort of data that is persisted between task runs. In
this tutorial we will only work with <strong>luigi.LocalTarget()</strong>'s, which
are normal files.</p>
<p>Tasks are defined as python classes that subclass the luigi.Task super
class. Each task has methods that the workflow designer is supposed to
implement:</p>
<ol>
<li><strong>requires() -</strong> should return one or more instantiated tasks that
the current task depends on.</li>
<li><strong>output()</strong> - return one or more targets objects, typically
representing files, the the current task will produce when run.</li>
<li><strong>run()</strong> - Here goes all the code that the task should run as its
job.</li>
</ol>
<p>In the run method, this is how we use the inputs and outputs to the
task:</p>
<ul>
<li>For the input, we use the special <strong>input()</strong> method, to get the
results of the <strong>output()</strong> function in our <strong>parent task</strong> (the
task that specified in <strong>requires()</strong>).</li>
<li>The outputs, we get (as luigi.LocalTarget objects), by simply
calling <strong>output().</strong></li>
</ul>
<h3 id="a-hello-world-task-in-luigi">A Hello World task in Luigi</h3>
<p>An example of a simple &quot;hello world&quot; luigi task (that just prints
&quot;Hello world&quot; in a new file), complete with the code required to run
the python file as a luigi script, looks like this:</p>
<pre><code>lang-python
import luigi

class HelloWorld(luigi.Task):
    def requires(self):
        return None
    def output(self):
        return luigi.LocalTarget('helloworld.txt')
    def run(self):
        with self.output().open('w') as outfile:
            outfile.write('Hello World!\n')

if __name__ == '__main__':
    luigi.run()
</code></pre>
<p>Type this into a file, named, say, <strong>luigitutorial.py</strong>, and let's try
to run it and see what happens!<br>
<br>
<em>(Note that since we don't have any dependencies for this task, we just
return <strong>None</strong> in the <strong>requires()</strong> method)</em><br>
<br>
To run the script, there are only two things you have to specify; A
scheduler host to use, and the name of the task to run. For now, lets
just use the &quot;<strong>--local-scheduler</strong>&quot; option, so that we don't need
to start a new scheduler, and of course, we specify the &quot;HelloWorld&quot;
that we have defined above:</p>
<pre><code>lang-bash
[samuel@milou2 luigitest]$ python luigitutorial.py --local-scheduler HelloWorld
DEBUG: Checking if HelloWorld() is complete
INFO: Scheduled HelloWorld() (PENDING)
INFO: Done scheduling tasks
INFO: Running Worker with 1 processes
DEBUG: Asking scheduler for work...
DEBUG: Pending tasks: 1
INFO: [pid 17513] Worker Worker(salt=160204304, host=milou2.uppmax.uu.se, username=sam***, pid=17513) running HelloWorld()
INFO: [pid 17513] Worker Worker(salt=160204304, host=milou2.uppmax.uu.se, username=sam***, pid=17513) done HelloWorld()
DEBUG: 1 running tasks, waiting for next task to finish
DEBUG: Asking scheduler for work...
INFO: Done
INFO: There are no more tasks to run at this time
INFO: Worker Worker(salt=160204304, host=milou2.uppmax.uu.se, username=sam***, pid=17513) was stopped. Shutting down Keep-Alive thread
</code></pre>
<p>Ah, did you notice that &quot;INFO: Done&quot; line there! Seems we are finally
set! Let's look if we have any new content in our folder:</p>
<pre><code>lang-bash
[samuel@milou2 luigitest]$ ls -ltr
total 64K
-rw-rw-r-- 1 samuel samuel 677 16 jan 17.52 luigitutorial.py
-rw-rw-r-- 1 samuel samuel 13 16 jan 17.58 helloworld.txt
</code></pre>
<p>Ah, cool, we have a new file &quot;helloworld.txt&quot; there! And what does it
contain:</p>
<pre><code>lang-bash
[samuel@milou2 luigitest]$ cat helloworld.txt 
Hello World!
</code></pre>
<p>Yay, exactly what we told it to contain!</p>
<p>Now you can sit back for a moment and contemplate the satisfaction of
just having written and ran your very first luigi workflow!
<img src="http://uppnex.se/twiki/pub/TWiki/SmiliesPlugin/smile.gif" alt="smile" title="smile"></p>
<h2 id="dependencies_paramsadding-dependencies-and-parameters">[]{#dependencies_params}Adding dependencies and parameters</h2>
<p>To add dependencies between tasks, we need one more task, and we need to
return something more than just None in the <strong>requires()</strong> function of
the downstream one. Let's try adding another task,<strong>NameSubstituter</strong>,
that will take the file we created in our <strong>HelloWorld</strong> task, and
replace &quot;World&quot; with some name.</p>
<p>But lets save time and take two steps in one, so let's take the name to
substitute with a parameter! So, look at how this looks, in the new
<strong>NameSubstituter</strong> class/task (the <strong>HelloWorld</strong> task remains
unchanged):</p>
<pre><code>lang-python
import luigi

class HelloWorld(luigi.Task):
    def requires(self):
        return None
    def output(self):
        return luigi.LocalTarget('helloworld.txt')
    def run(self):
        with self.output().open('w') as outfile:
            outfile.write('Hello World!\n')

class NameSubstituter(luigi.Task):
    name = luigi.Parameter()

    def requires(self):
        return HelloWorld()
    def output(self):
        return luigi.LocalTarget(self.input().path + '.name_' + self.name)
    def run(self):
        with self.input().open() as infile, self.output().open('w') as outfile:
            text = infile.read()
            text = text.replace('World', self.name)
            outfile.write(text)

if __name__ == '__main__':
    luigi.run()
</code></pre>
<p>Above you can see in the <strong>requires()</strong> method of the
<strong>NameSubstituter</strong> task, how we return the previous task
(<strong>HelloWorld</strong> in this case) and in the <strong>run()</strong> method, we open it as
our infile, read it, replace &quot;World&quot; with some name that we get from
the luigi parameter, and then write it out to the output target of
<strong>NameSubstituter</strong>.</p>
<ul>
<li><strong>Stop and think:</strong> What will be the file name of the newly
generated file, can you see that from the code?</li>
</ul>
<p>Let's try to run the new task, and see what we get:</p>
<pre><code>lang-bash
[samuel@milou2 luigitest]$ python luigitutorial.py --local-scheduler NameSubstituter
Traceback (most recent call last):
  File &quot;luigitutorial.py&quot;, line 28, in &lt;module&gt;
    luigi.run()
  File &quot;/home/samuel/.pyenv/versions/2.7.6/lib/python2.7/site-packages/luigi/interface.py&quot;, line 451, in run
    tasks = interface.parse(cmdline_args, main_task_cls=main_task_cls)
  File &quot;/home/samuel/.pyenv/versions/2.7.6/lib/python2.7/site-packages/luigi/interface.py&quot;, line 309, in parse
    return self.parse_task(cmdline_args, main_task_cls)
  File &quot;/home/samuel/.pyenv/versions/2.7.6/lib/python2.7/site-packages/luigi/interface.py&quot;, line 304, in parse_task
    task = task_cls.from_str_params(params, Register.get_global_params())
  File &quot;/home/samuel/.pyenv/versions/2.7.6/lib/python2.7/site-packages/luigi/task.py&quot;, line 382, in from_str_params
    value = param.parse_from_input(param_name, params_str[param_name])
  File &quot;/home/samuel/.pyenv/versions/2.7.6/lib/python2.7/site-packages/luigi/parameter.py&quot;, line 252, in parse_from_input
    (param_name, &quot;--&quot; + param_name.replace('_', '-')))
luigi.parameter.MissingParameterException: No value for 'name' (--name) submitted and no default value has been assigned.
</code></pre>
<p>Oops! Did you see that last line?</p>
<p>Of course, if we create a parameter to the task, we need to provide the
value for the parameter as well! And the output suggests how to do it:
Just add <strong>&quot;--name &lt;the-value-of-the-parameter&gt;&quot;</strong>. Let's try
again:</p>
<pre><code>lang-bash
[samuel@milou2 luigitest]$ python luigitutorial.py --local-scheduler NameSubstituter --name samuel
DEBUG: Checking if NameSubstituter(name=samuel) is complete
INFO: Scheduled NameSubstituter(name=samuel) (PENDING)
DEBUG: Checking if HelloWorld() is complete
INFO: Scheduled HelloWorld() (DONE)
INFO: Done scheduling tasks
INFO: Running Worker with 1 processes
DEBUG: Asking scheduler for work...
DEBUG: Pending tasks: 1
INFO: [pid 9019] Worker Worker(salt=493027103, host=milou2.uppmax.uu.se, username=sam***, pid=9019) running   NameSubstituter(name=samuel)
INFO: [pid 9019] Worker Worker(salt=493027103, host=milou2.uppmax.uu.se, username=sam***, pid=9019) done      NameSubstituter(name=samuel)
DEBUG: 1 running tasks, waiting for next task to finish
DEBUG: Asking scheduler for work...
INFO: Done
INFO: There are no more tasks to run at this time
INFO: Worker Worker(salt=493027103, host=milou2.uppmax.uu.se, username=sam***, pid=9019) was stopped. Shutting down Keep-Alive thread
</code></pre>
<p>Well, that looks WAY better! (We get that &quot;<strong>Done</strong>&quot; line in the
bottom).</p>
<p>And, we can also have a look at what files have been generated now (we
use the -ltr flags, to list files in order of modification time, in
ascending order):</p>
<pre><code>lang-bash
[samuel@milou2 luigitest]$ ls -ltr
total 96K
-rw-rw-r-- 1 samuel samuel 748 16 jan 19.28 luigitutorial.py
-rw-rw-r-- 1 samuel samuel 13 16 jan 19.31 helloworld.txt
-rw-rw-r-- 1 samuel samuel 14 16 jan 19.31 helloworld.txt.name_samuel
</code></pre>
<p>Did you guess right about the name of that last file?</p>
<p>Did you notice how we simply <strong>padded</strong> a new string to the file name of
the target from our parent task? It turns out that this is in fact a
highly useful pattern, since it helps us keep track of what tasks have
been ran in order to produce a particular file, and also the values of
the parameters to those tasks, if we choose to include them, like we did
with the <strong>name</strong> parameter here.</p>
<h2 id="visualizevisualizing-running-workflows-optional">[]{#visualize}Visualizing running workflows (optional)</h2>
<p>Before we go further into more advanced topics, lets see if we can get
the web based workflow visualization going, so that we can keep track of
what's happening in a visual way!</p>
<p>In order to see what's happening before the workflow is finished, we
need to add a little sleep to the tasks, since they are running so fast.
So, let's add a sleep of 15 seconds before and after the main chunk of
work in each of the tasks:</p>
<pre><code>lang-python
import luigi
import time

class HelloWorld(luigi.Task):
    def requires(self):
        return None
    def output(self):
        return luigi.LocalTarget('helloworld.txt')
    def run(self):
        time.sleep(15)
        with self.output().open('w') as outfile:
            outfile.write('Hello World!\n')
        time.sleep(15)

class NameSubstituter(luigi.Task):
    name = luigi.Parameter()

    def requires(self):
        return HelloWorld()
    def output(self):
        return luigi.LocalTarget(self.input().path + '.name_' + self.name)
    def run(self):
        time.sleep(15)
        with self.input().open() as infile, self.output().open('w') as outfile:
            text = infile.read()
            text = text.replace('World', self.name)
            outfile.write(text)
        time.sleep(15)

if __name__ == '__main__':
    luigi.run()
</code></pre>
<p>What we also need to do, in order to view the web UI, is to run the
luigi daemon, not just the local-scheduler as before:</p>
<p>So, in a separate terminal / SSH window, start up the daemon:</p>
<pre><code>lang-bash
luigid
</code></pre>
<p>Then, in a browser, fire up the following web address:</p>
<ul>
<li><a href="http://localhost:8082/">http://localhost:8082<img src="http://uppnex.se/twiki/pub/TWiki/TWikiDocGraphics/external-link.gif" alt=""></a></li>
</ul>
<p>Then, in a separate terminal window, start the luigi workflow we created
above, now specifying &quot;<strong>localhost</strong>&quot; as our
&quot;<strong>--scheduler-host</strong>&quot;:</p>
<pre><code>lang-bash
python luigitutorial.py --scheduler-host localhost NameSubstituter --name YourName
</code></pre>
<p>Now, go back to <a href="http://localhost:8082/">http://localhost:8082</a>,
refresh, and see what you see!</p>
<p>If everything works correctly, you should see something like this:</p>
<p><img src="/site/assets/files/1068/luigi_task_status.480x0-is.png" alt=""></p>
<p>Click on the button indicated in the screenshot above!</p>
<p>Then you should see something like this, representing a (very minimal)
&quot;dependency graph&quot; of our two tasks:</p>
<p><img src="/site/assets/files/1068/luigi_task_status2.480x0-is.png" alt=""></p>
<h2 id="reusere-using-components-in-multiple-workflows">[]{#reuse}Re-using components in multiple workflows</h2>
<h3 id="the-default-way-sub-classing">The default way: Sub-classing</h3>
<p>The simplest way to re-use luigi components, is to just subclass an
existing task class, and override it's requires() method.</p>
<p>See for example this code example, where we have a <strong>TaskA</strong> and
<strong>TaskB</strong>, and then a <strong>TaskC</strong> that depends on <strong>TaskA</strong>.</p>
<p>Then, in the bottom, we have subclassed <strong>TaskC</strong> into <strong>MyTaskC</strong>, and
by overriding the requires() method, changed the dependency from
<strong>TaskA</strong> to <strong>TaskB</strong>:</p>
<pre><code>lang-python
import luigi

class TaskA(luigi.Task):
    def requires(self):
        return None
    def output(self):
        return luigi.LocalTarget('task_a')
    def run(self):
        with self.output().open('w') as outfile:
            outfile.write('foo')

class TaskB(luigi.Task):
    def requires(self):
        return None
    def output(self):
        return luigi.LocalTarget('task_b')
    def run(self):
        with self.output().open('w') as outfile:
            outfile.write('bar')


class TaskC(luigi.Task):
    def requires(self):
        return TaskA() # &lt;-- Notice this dependency!
    def output(self):
        return luigi.LocalTarget(self.input().path + '.task_c')
    def run(self):
        with self.input().open() as infile, self.output().open('w') as outfile:
            for line in infile:
                outfile.write(line)
    

# Let's create an own &quot;copy&quot; of TaskC, that depends on TaskB instead of TaskA:

class MyTaskC(TaskC):
    def requires(self):
        return TaskB() # &lt;-- Notice how we switched the dependency in TaskC!

if __name__ == '__main__':
    luigi.run()
</code></pre>
<p>Try now to run this workflow, by executing the last task in the
workflow:</p>
<pre><code>lang-bash
[samuel]$ python luigi_reuse_depinject.py --local-scheduler TaskC 
</code></pre>
<h3 id="an-other-more-dynamic-way">An other, more dynamic, way</h3>
<p>The default way of re-using luigi tasks, by sub-classing, as
demonstrated above, but for reasons we will not go into depth about here
(but that you can read more about in <a href="https://medium.com/@saml/loosely-coupled-tasks-in-luigi-workflows-6840d32e2824">this blog
post</a>),
we need a more flexible and dynamic way of building up workflows based
on existing luigi tasks.</p>
<p>Based on our experimentation, we have found that the following method
works very well:</p>
<pre><code>lang-python
import luigi

class TaskA(luigi.Task):
    def requires(self):
        return None
    def output(self):
        return luigi.LocalTarget('task_a')
    def run(self):
        with self.output().open('w') as outfile:
            outfile.write('foo')

class TaskB(luigi.Task):
    def requires(self):
        return None
    def output(self):
        return luigi.LocalTarget('task_b')
    def run(self):
        with self.output().open('w') as outfile:
            outfile.write('bar')

class TaskC(luigi.Task):
    upstream_task = luigi.Parameter(default=TaskA()) # &lt;-- Notice how we set the upstream dependency as a luigi task!
    def requires(self):
        return self.upstream_task # &lt;-- Notice this dependency!
    def output(self):
        return luigi.LocalTarget(self.input().path + '.task_c')
    def run(self):
        with self.input().open() as infile, self.output().open('w') as outfile:
            for line in infile:
                outfile.write(line)

# Let's create a workflow task &quot;MyWorkflow&quot;, that requires TaskC, but with a 
# different upstream dependency (TaskB) instead of the default TaskA
class MyWorkflow(luigi.Task):
    def requires(self):
        return TaskC(
          upstream_task=TaskB() # &lt;-- Notice how we switched the dependency in TaskC!
        )
    def output(self):
        return self.input()

if __name__ == '__main__':
    luigi.run()
</code></pre>
<p>Notice in <strong>TaskC</strong> above, how we are taking the upstream dependency as
a parameter, rather than hard-coding it! This makes it possible to
change how the workflow is connected together, at any time.</p>
<p>Notice also, in the <strong>MyWorkflow</strong> task, how we have created this task
just for the sake of encapsulating the workflow - it does not even
implement any run() method!</p>
<p>Try now, after deleting the previously created output, to run this
workflow, by executing our new and special &quot;workflow task&quot;,
<strong>MyWorkflow</strong>:</p>
<pre><code>lang-bash
[samuel]$ python luigi_reuse_depinject.py --local-scheduler MyWorkflow
</code></pre>
<p>... and verify that the result is still the same!</p>
<h3 id="a-note-on-passing-parameters">A note on passing parameters</h3>
<p>You might not have realized it yet, but the second method will prove to
be much much preferable to the first one for a number of reasons. One of
those reasons is that for tasks that take parameters, it will be much
easier to create modular workflows that don't require changes in any of
the tasks themselves, when re-using tasks in new workflows.</p>
<p>Consider the following (sketchy) example luigi workflow, created using
the first, sub-classing, approach:</p>
<pre><code>lang-python
class TaskA(luigi.Task):
  param1 = luigi.Parameter()
  ... 
 
class TaskB(luigi.Task):
  param1 = luigi.Parameter()
  param2 = luigi.Parameter()  
  def requires(self):
    return TaskA(param1=self.param1)
  ...
 
class TaskC(luigi.Task):
  param1 = luigi.Parameter()
  param2 = luigi.Parameter()  
  param3 = luigi.Parameter()  
  def requires(self):
    return TaskA(param1=self.param1, 
                 param2=self.param2)
  ...
 
class TaskD(luigi.Task):
  param1 = luigi.Parameter()
  param2 = luigi.Parameter()  
  param3 = luigi.Parameter()  
  param4 = luigi.Parameter()  
  def requires(self):
    return TaskA(param1=self.param1, 
                 param2=self.param2,
                 param3=self.param3)
  ...
</code></pre>
<p>Do you notice how parameters introduced higher up in the &quot;workflow
graph&quot;, have to be duplicated all the way down to the last task,
<strong>TaskD</strong>, and passed along, through all intermediate tasks?</p>
<p>Can you imagine what happens e.g. if we want to add an existing task
somewhere in the middle, e.g. between <strong>TaskB</strong> and <strong>TaskC</strong>? - Then we
need to firstly add all the parameters which need just need to &quot;pass
through&quot; this task, until it reaches its upstream goal. But secondly,
if that new task takes any parameters, we will also need to duplicate
those parameters in all downstream tasks (in this case <strong>TaskC</strong> and
<strong>TaskD</strong>), in order to be able to execute the whole workflow?</p>
<p>Do you see how the tasks are no longer interchangeable, and truly
modular?</p>
<p>Then, consider the following workflow, where instead, each task just
contains its own parameter(s), and those parameters are only duplicated
(once) if / when the task is used in a &quot;workflow task&quot;, along the line
of our example further above:</p>
<pre><code>lang-python
class TaskA(luigi.Task):
    param1 = luigi.Parameter()
    ... 
 
class TaskB(luigi.Task):
    param2 = luigi.Parameter()    
    ...
 
class TaskC(luigi.Task):
    param3 = luigi.Parameter()    
    ...
 
class TaskD(luigi.Task):
    param4 = luigi.Parameter()    
    ...

class MyWorkflow(luigi.Task):
    param1 = luigi.Parameter()
    param2 = luigi.Parameter()
    param3 = luigi.Parameter()
    param4 = luigi.Parameter()
    
    def requires(self):
        task_a = TaskA(
            param1 = self.param1)        
        task_b = TaskB(
            upstream_task = task_a
            param2 = self.param2)        
        task_c = TaskC(
            upstream_task = task_b
            param3 = self.param3)        
        task_d = TaskD(
            upstream_task = task_c
            param4 = self.param4)        
        return task_d
        
    def output(self):
        return self.input()
</code></pre>
<p>Do you see now how the tasks themselves never need to change, and so
become completely modular, easy to stitch in to any workflow?</p>
<p>(We will continue improving on this scheme in the next section, where we
look at how to handle multiple inputs and outputs to tasks)</p>
<h2 id="multi_input_outputa-solution-for-multiple-inputs-and-outputs">[]{#multi_input_output}A solution for multiple inputs and outputs</h2>
<p>One can return multiple outputs (and take multiple inputs) in tasks in
luigi, by letting the <strong>output()</strong> function of a task return a list, but
even better, a dict, with luigi.Target()'s.</p>
<p>Below is an example of how <strong>TaskB</strong> can depend on two outputs from
<strong>TaskA</strong> (So <strong>TaskA</strong> 's two outputs, become <strong>TaskB</strong> 's two
inputs):</p>
<pre><code>lang-python
import luigi

class TaskA(luigi.Task):
    def requires(self):
        return None
    def output(self):
        return {'output1' : luigi.LocalTarget('task_a_out1'),
                'output2' : luigi.LocalTarget('task_a_out2')}
    def run(self):
        with self.output().open('w') as outfile:
            outfile.write('foo\n')

class TaskB(luigi.Task):
    def requires(self):
        return TaskA()
    def output(self):
        return luigi.LocalTarget('task_a')
    def run(self):
        with self.input()['output1'].open() as infile1: # Notice how we need to know the name of TaskA's output
            with self.input()['output2'].open() as infile2: # ... and same here ...
                with self.output().open('w') as outfile:
                    for line in infile1:
                        outfile.write(line)
                    for line in infile2:
                        outfile.write(line)

if __name__ == '__main__':
    luigi.run()
</code></pre>
<p>But, do you notice anything strange here?</p>
<p>Do you notice how, in the run() method of <strong>TaskB</strong>, we have to know the
names of the outputs of <strong>TaskA</strong> ... which is of course less than
optimal, since now we have to know internals of another task inside our
task. Then our tasks are no longer independent and truly modular.</p>
<p>But this is not even the worst we can get ... look at what happens when
one task (<strong>TaskC</strong> in this case) depends on TWO upstream tasks, EACH OF
WHICH returns two outputs. Then we have to look up two dict structures
(the dict returned from our requires() method, and the one returned from
each upstream tasks output() function):</p>
<pre><code>lang-python
import luigi

class TaskA(luigi.Task):
    def requires(self):
        return None
    def output(self):
        return {'output1' : luigi.LocalTarget('task_a_out1'),
                'output2' : luigi.LocalTarget('task_a_out2')}
    def run(self):
        with self.output()['output1'].open('w') as outfile:
            outfile.write('foo\n')
        with self.output()['output2'].open('w') as outfile:
            outfile.write('foo\n')

class TaskB(luigi.Task):
    def requires(self):
        return None
    def output(self):
        return {'output1' : luigi.LocalTarget('task_b_out1'),
                'output2' : luigi.LocalTarget('task_b_out2')}
    def run(self):
        with self.output()['output1'].open('w') as outfile:
            outfile.write('bar\n')
        with self.output()['output2'].open('w') as outfile:
            outfile.write('bar\n')


class TaskC(luigi.Task):
    def requires(self):
        return {'input_a' : TaskA(),
                'input_b' : TaskB()}
    def output(self):
        return luigi.LocalTarget(self.input()['input_a']['output1'].path + '.task_c')
    def run(self):
        with self.input()['input_a']['output1'].open() as infile_a1: # Notice how we need to know the name of TaskA's output
            with self.input()['input_a']['output2'].open() as infile_a2: # ... and same here ...
                with self.input()['input_b']['output1'].open() as infile_b1: # Notice how we need to know the name of TaskA's output
                    with self.input()['input_b']['output2'].open() as infile_b2: # ... and same here ...
                        with self.output().open('w') as outfile:
                            for line in infile_a1:
                                outfile.write(line)
                            for line in infile_a2:
                                outfile.write(line)
                            for line in infile_b1:
                                outfile.write(line)
                            for line in infile_b2:
                                outfile.write(line)

if __name__ == '__main__':
    luigi.run()
</code></pre>
<p>(notice the double dict look ups, in the run method ... for example
<strong>self.input()['input_a']['output1'].open() as infile_a1</strong>
... I guess you can notice how this also gets rather messy after a
while)</p>
<h3 id="a-solution">A solution</h3>
<p>The way we have found to work around this, is the following:</p>
<ul>
<li>Don't send upstream dependencies as parameters, like we suggested
in an earlier section.</li>
<li>Instead, just send (as a parameter) a dict-structure containing the
upstream task, and the name of the output, to &quot;plug into&quot; this
task.</li>
<li>Make one such parameter per &quot;input&quot; that the task will use.</li>
<li>Create a special method get_input(), stored in a meta class, that
can be used to retrieve the correct input, based on the dict
structures sent as parameters.</li>
</ul>
<p>Part of what we solve here, is also that, instead of specifying
dependencies <strong>between tasks</strong>, we specify how tasks depend on, and
export, <strong>targets</strong>.</p>
<p>Let's look at how our solution looks in code:</p>
<pre><code>lang-python
###### Meta class ######
 
class DependencyMetaTask(luigi.Task):
    # METHODS FOR AUTOMATING DEPENDENCY MANAGEMENT
    def requires(self):
        upstream_tasks = []
        for param_val in self.param_args:
            if type(param_val) is dict:
                if 'upstream' in param_val:
                    upstream_tasks.append(param_val['upstream']['task'])
        return upstream_tasks
 
    def get_input(self, input_name):
        param = self.param_kwargs[input_name]
        if type(param) is dict and 'upstream' in param:
            return param['upstream']['task'].output()[param['upstream']['port']]
        else: 
            return param
 
 
###### Normal classes ######
 
class TaskA(DependencyMetaTask):
    # INPUT TARGETS
    in1_target = luigi.Parameter()
    param_a1 = luigi.Parameter()
 
   # DEFINE OUTPUTS
    def output(self):
        return { 'out1' : 
            luigi.LocalTarget(
                self.get_input('in1_target').path + '.out1'),
                 'out2' : 
            luigi.LocalTarget(
                self.get_input('in1_target').path + '.out2') } }
 
    # WHAT THE TASK DOES
    def run(self):
        with open(self.get_input('in1_target').path) as infile:
            for line in infile:
                do_something(line)
 
 
class TaskB():
    # INPUT TARGETS
    in1_target = luigi.Parameter()
    in2_target = luigi.Parameter()
    param_b1 = luigi.Parameter()
    param_b2 = luigi.Parameter()
 
    def run(self):
        # Do something with both in1 and in2
        ....
 
##### THE ACTUAL WORKFLOW / DEPENDENCY GRAPH DEFINITION #####
 
class MyWorkFlow(luigi.Task):
    # We only need to duplicate all parameters 
    # once, which is here in the workflow task
    param_a1 = luigi.Parameter()
    param_b1 = luigi.Parameter()
    param_b2 = luigi.Parameter()
 
    # Here the whole workflow definition resides:
    def requires(self):
        task_a = TaskA( 
            param_a1 = self.param_a1 
        )
 
        task_b = TaskB( 
            param_b1 = self.param_b1,
            param_b2 = self.param_b2,
            # Here below, we connect the output out1 from TaskA
            # to in1_target of TaskB ...
            in1_target = 
                { 'upstream' : { 'task' : task_a,
                                 'port' : 'out1' } }
            # ... and again, out2 of TaskA, to in2_target of
            # TaskB, using our special syntax.
            in2_target = 
                { 'upstream' : { 'task' : task_a,
                                 'port' : 'out2' } }
        )
</code></pre>
<p>So, can you follow what happens here?</p>
<p>The key here is the get_input() method in the <strong>DependencyMetaTask</strong>
meta class. It allows us to send as parameters to tasks, a double dict
structure looking like so:</p>
<pre><code>lang-bash
some_target = { 'upstream' : { 'task' : TaskA() , 'port' : 'output1' } }
</code></pre>
<p>... just a little differently formatted above.</p>
<p>Then, as you can see in the run() method of <strong>TaskA</strong> above, we can just
use the get_input() function to get a specific input target (and not
just a dependent task, or dict of tasks, like with the normal input()
method).</p>
<p>Maybe you also notice that this lets us do all the wiring of how outputs
from <strong>TaskA</strong> is mapped to &quot;inputs&quot; (those special parameters which
take a specification for how to find a certain target), in <strong>TaskB</strong>. In
effect we have <strong>separated the workflow definition from the tasks
themselves</strong>, and thereby made the tasks wholly independent and truly
modular, just as we sought to do.</p>
<h2 id="commandsexecuting-commands">[]{#commands}Executing commands</h2>
<p>In Luigi, it is very easy to implement a task's run() method with just
some python code that does something.</p>
<p>But in bioinformatics, most of the time we want to execute some external
program, that is accessible only via its command line interface.</p>
<p>This is also no problem in python, as you might expect, but we have
found that creating some small helper functions can help a lot in making
this easier to work with.</p>
<p>We typically create a <strong>MetaTask</strong> or Mixin, with helper functions such
as one for executing commands, and let all tasks subclass (or &quot;mix in&quot;
the mixin). Below you find our implementation of a helper function for
executing commands, and how to use it:</p>
<pre><code>lang-python
import luigi
import commands

class TaskHelpers():
    # We here show the simplest version needed to execute commands in our preferred way:
    def execute_command(self, command):
        return commands.getstatusoutput(command)

    # And we can also have a really short &quot;alias&quot; of the execute_command method
    def x(self, command):
        return self.execute_command(command)


# Then we can use the above TaskHelper mixin, like this (taken from a real-world example):
class GenerateFingerPrint(luigi.Task, TaskHelpers):
    # INPUT TARGETS
    dataset_target = luigi.Parameter()

    # PARAMETERS
    fingerprint_type = luigi.Parameter()

    # DEFINE OUTPUTS
    def output(self):
        return { 'fingerprints' : luigi.LocalTarget(self.get_input('dataset_target').path + '.' + self.fingerprint_type + '.csr') }

    def run(self):
        self.x([JAVA_PATH, '-jar jars/FingerprintsGenerator.jar',
                '-fp', self.fingerprint_type,
                '-inputfile', self.get_input('dataset_target').path,
                '-parser', '1',
                '-outputfile', self.output()['fingerprints'].path])
</code></pre>
<p>In the run method of the <strong>GenerateFingerPrint</strong> task, you see how we
can execute commands by sending a python list of command parts, to the
x() method, for execution (we could send a string as well, but a list of
command parts has turned out to be easier to work with, when many of the
parts are dynamically generated from input file names, parameters etc.)</p>
<p>So, this last example show a pretty authentic real-world example of how
we are using Luigi at <a href="http://www.farmbio.uu.se/forskning/researchgroups/pb/Data-intensive/">UU/Dept. of Pharmaceutical Bio
sciences</a>.</p>

  


  </main>
  <footer>
    <p>Copyright 2024. All rights reserved.</p>

  </footer>
</body>
</html>
