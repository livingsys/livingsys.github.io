<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Engineering on Living Systems</title>
    <link>https://livingsystems.se/tags/data-engineering/</link>
    <description>Recent content in Data Engineering on Living Systems</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 21 Jun 2016 13:49:00 +0200</lastBuildDate>
    <atom:link href="https://livingsystems.se/tags/data-engineering/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Tutorial: Luigi for Scientific Workflows</title>
      <link>https://livingsystems.se/posts/luigi-tutorial/</link>
      <pubDate>Tue, 21 Jun 2016 13:49:00 +0200</pubDate>
      <guid>https://livingsystems.se/posts/luigi-tutorial/</guid>
      <description>This is a Luigi tutorial I held at the e-Infrastructures for Massively parallel sequencing workshop (Video archive ) at SciLifeLab Uppsala in January 2015, moved here for future reference.&#xA;What is Luigi? Luigi is a batch workflow system written in Python and developed by Erik Bernhardson and others at Spotify , where it is used to compute machine-learning powered music recommendation lists, top lists etc.&#xA;Luigi is one of not-too-many batch workflow systems that supports running both normal command line jobs and Hadoop jobs in the same (in this tutorial, we will focus only on the command line part).</description>
    </item>
  </channel>
</rss>
